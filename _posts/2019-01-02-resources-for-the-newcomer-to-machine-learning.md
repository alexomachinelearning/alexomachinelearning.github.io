---
layout: post
title: "Resources for the Newcomer to Machine Learning"
date:   2019-01-02 13:02:00 -0800
redirect_from:
  - /2019-01-02-resources-for-the-newcomer-to-machine-learning.html
---
Learning how to learn something new is always tricky. It's a bit like figuring out how to build a shelf to put new knowledge on before you know what kind of knowledge you'll acquire, how long or high the shelves should be, or which tools you'll need to build the shelves themselves.

I guess sometimes the best way to start is to, well, start. You build as you go, and you ask to borrow tools as needed or help building shelves when you need to. You also determine what's irrelevant to your aims or too far beyond your current knowledge horizon to be useful now. That's the game of unstructured trial and error—the human version of reinforcement learning. But first, you must start.

One way to divide the start is by segment, i.e., by source or type of resource:

* Books to read
* People to follow
* Courses to take

And so forth.

## __Learning Segments__

Below are some of the machine learning resources that I've come across so far or have been suggested to me. This list is unprioritized and inexhaustive. It is a snapshot in time, so I do not anticipate adding to this list in the future.

## Books

* [_An Introduction to Statistical Learning with Applications in R_](https://www.amazon.com/gp/product/1461471370){:rel="nofollow"} by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
* [_The Elements of Statistical Learning: Data Mining, Inference, and Prediction_](https://www.amazon.com/gp/product/0387848576){:rel="nofollow"} by Trevor Hastie, Robert Tibshirani, and Jerome Friedman
* [_Fuzzy Sets and Fuzzy Logic: Theory and Applications_](https://www.amazon.com/gp/product/0131011715){:rel="nofollow"} by George J. Klir and Bo Yuan
* [_Life 3.0: Being Human in the Age of Artificial Intelligence_](https://www.amazon.com/gp/product/1101970316){:rel="nofollow"} by Max Tegmart
* [_Machine Learning: The New AI_](https://www.amazon.com/gp/product/0262529513){:rel="nofollow"} by Ethem Alpaydin
* [_The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World_](https://www.amazon.com/gp/product/0465065708){:rel="nofollow"} by Pedro Domingos
* [_Nexus (The Nexus Trilogy Book 1)_](https://www.amazon.com/gp/product/B00TOZI7FM){:rel="nofollow"} by Ramez Naam (this is the only fiction book on the list)
* [_Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering_](https://www.amazon.com/gp/product/0813349109){:rel="nofollow"} by Steven H. Strogatz
* [_On Intelligence: How a New Understanding of the Brain Will Lead to the Creation of Truly Intelligent Machines_](https://www.amazon.com/Intelligence-Jeff-Hawkins-dp-0805074562/dp/0805074562){:rel="nofollow"} by Jeff Hawkins and Sandra Blakeslee
* [_Our Mathematical Universe: My Quest for the Ultimate Nature of Reality_](https://www.amazon.com/gp/product/0307744256){:rel="nofollow"} by Max Tegmart

## Courses

* [_Applying Machine Learning to your Data with GCP_](https://www.coursera.org/learn/data-insights-gcp-apply-ml) by Google Cloud Training at _Coursera_
* ["In-depth Introduction to Machine Learning in 15 Hours of Expert Videos"](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/) by Kevin Markham (2014) at _R-bloggers_ or [_DataSchool.io_](https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/) (this supplementary resource comes highly recommended and includes the slides and videos to a course by the authors of _An Introduction to Statistical Learning with Applications in R_, above)
* [_Neural Networks and Deep Learning_](https://www.coursera.org/learn/neural-networks-deep-learning)  by Andrew Ng, Kian Katanforoosh, and Younes Bensouda Mourri at _Coursera_
* [_Neural Networks for Machine Learning — Geoffrey Hinton 2016_](https://www.youtube.com/playlist?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9), a 78-video playlist by Colin McDonnell at _Youtube_ (the Coursera course itself appears to no longer be available)

## Long Reads

* ["Markov Chain Monte Carlo Methods, Rejection Sampling and the Metropolis-Hastings Algorithm"](http://bjlkeng.github.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/) by Brian Keng (2015) at _Bounded Rationality_
* ["Markov Chain Monte Carlo Models, Gibbs Sampling, & Metropolis Algorithm for High-Dimensionality Complex Stochastic Problems"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2553537) by Yogesh Malhotra (2015) in _The SSRN_
* ["Marvin Minsky's Vision of the Future" / "A.I."](https://www.newyorker.com/magazine/1981/12/14/a-i) by Jeremy Bernstein (1981) in _The New Yorker_
* ["Neuralink and the Brain’s Magical Future"](https://waitbutwhy.com/2017/04/neuralink.html) by Tim Urban (2017) in _Wait But Why_
* ["Neuroscience-Inspired Artificial Intelligence"](https://doi.org/10.1016/j.neuron.2017.06.011) by Demis Hassabis, Dharshan Kumaran, Christopher Summerfield, and Matthew Botvinick (2017) in _Neuron_
* ["One Giant Step for a Chess-Playing Machine"](https://www.nytimes.com/2018/12/26/science/chess-artificial-intelligence.html) by Steven Strogatz (2018) in _The New York Times_
* ["Progress Report on Artificial Intelligence"](https://web.media.mit.edu/~minsky/papers/PR1971.html) by Marvin Minsky and Seymour Papert (1971) at _MIT_

## People

* [Pieter Abbeel](http://people.eecs.berkeley.edu/~pabbeel/) - Berkeley reinforcement learning researcher
* [Francois Chollet](https://ai.google/research/people/105096) - inventor of the Keras neural network library
* [Lex Fridman](https://lexfridman.com/) - MIT research scientist and AI podcast host
* [Demis Hassabis](https://twitter.com/demishassabis) - co-founder of artificial general intelligence research company DeepMind
* [Andrej Karpathy](https://cs.stanford.edu/people/karpathy/) - Tesla's AI Director with a focus on Autopilot perception
* [Fei-Fei Li](http://vision.stanford.edu/feifeili/) - Stanford professor and computer vision expert
* [Andrew Ng](https://www.andrewng.org/) - professor, co-founder of Coursera, & deep learning expert
* [Carol Reiley](http://www.creiley.com/) - roboticist and co-founder of autonomous driving company drive.ai
* [Daniela Rus](https://www.csail.mit.edu/person/daniela-rus) - roboticist and Director of MIT's famed CSAIL laboratory


## Miscellaneous Topics

* How the class of problems you wish to solve impact your choice of learning model, machine learning algorithm, and neural networks
* How the computational expensiveness of certain neural network calculations (e.g. matrix multiplication) constrains your choice of software and hardware (i.e., the GPU-friendliness vs CPU-friendliness of machine learning)
* The impact your choice of programming languages to learn (e.g. C++ vs Python or JavaScript or R) has on the tools and libraries you later use
* Which data sets to use to train your learning models
* Which neural networks are optimal for making predictions on inputs of certain sorts, e.g., videos vs static images vs speech vs text
* As with distributed systems and decentralized blockchains, the fit between what problems you want to solve and what combination of solutions (per above) to employ


## Tidbits
* Lex Fridman's podcast, [_Artificial Intelligence Podcast_](https://lexfridman.com/ai/), features interviews with the above-mentioned Pieter Abbeel and Max Tegmart as well as many others in the ML and AI spaces
* The subject of [generative adversarial networks (GANs)](https://en.wikipedia.org/wiki/Generative_adversarial_network) is apparently a hot area of research
* 3Blue1Brown's video ["But what IS a Neural Network?"](https://www.youtube.com/watch?v=aircAruvnKk) is the best video I've yet seen on perceptrons and the structure & purpose of neural networks
* ["Deep Learning Cars"](https://www.youtube.com/watch?v=Aut32pR5PQA) is a video by Samuel Artz that simulates, in 2D, cars on a race course. In the video's description is a link to the source code for the simulation
* Toronto computer hardware company [Xanadu](https://www.xanadu.ai/) is working on advanced AI and "photonic quantum computing" chips to enable quantum applications of machine learning
* For some excellent visuals and explanations of various neural network architectures, see the articles ["The Neural Network Zoo Prequel: Cells and Layers"](http://www.asimovinstitute.org/neural-network-zoo-prequel-cells-layers/) and ["The Neural Network Zoo"](http://www.asimovinstitute.org/neural-network-zoo/) by AI research company The Asimov Institute. You can also read Andrew Tchircoff's ["The mostly complete chart of Neural Networks, explained"](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464) at _Towards Data Science_
* Some neural networks can be run inside phone applications and are bundled in a file with special extensions (e.g., _.mlmodel_ for apps running MLModel on the iPhone or _.tflite_ for apps running TensorFlow Lite on Android devices). So, by example, iPhone developers can [integrate machine learning models into their apps](https://developer.apple.com/documentation/coreml) by using Apple's Core ML framework, the Core ML API, and the _MLModel class_. The key point is that some neural networks work with the limited resources of a CPU on something like an iPhone, which is amazing, and perhaps a stepping stone to neural networks running on even lower-power IoT devices in the future.
* Amazon AWS Machine Learning currently supports three [types of machine learning models](https://docs.aws.amazon.com/machine-learning/latest/dg/types-of-ml-models.html), namely _binary classification_, _multiclass classification_, and _regression_, each of which is ideal for making different types of predictions
* _Game theory_; _complexity theory_; _statistics_ of many kinds, as well as major statistical theories (e.g., Bayesian) and related techniques (e.g., regression); _linear algebra_, and other academic disciplines appear to be important layers to the work of artificial intelligence. That is very interesting, something machine learning technologies appear to share with decentralized systems (blockchains): to work, they must draw on principles from economics, statistics, computer science, and mathematics
* Some universities offer not only free online courses but also paid certificate programs, such as [MIT Online's professional education](https://professionalonline1.mit.edu/machine-learning/index.php) and [Stanford Online's graduate education](https://online.stanford.edu/programs/artificial-intelligence-graduate-certificate), in various sub-areas of machine learning
* For a short technical introduction to _prior distributions_, _likelihood functions_, & _posterior probabilities_ in the software Stata, see Chuck Huber's video ["Introduction to Bayesian statistics, part 1: The basic concepts"](https://www.youtube.com/watch?v=0F0QoMCSKJ4)
* The _MIT Sloan Management Review_ article ["The Machine Learning Race Is Really a Data Race"](https://sloanreview.mit.edu/article/the-machine-learning-race-is-really-a-data-race/) by Megan Beck and Barry Libert raises good questions about the importance of unique data to train machine learning models used in commercial applications



## Tools
* [Amazon Machine Learning](https://aws.amazon.com/machine-learning/)
* [Azure Machine Learning Studio](https://azure.microsoft.com/en-us/services/machine-learning-studio/)
* [Caffe](http://caffe.berkeleyvision.org/) & [Caffe2](https://caffe2.ai/)
* [Colaboratory](https://colaboratory.jupyter.org)
* [DataCamp](https://www.datacamp.com)
* [Google Cloud AI & Machine Learning](https://cloud.google.com/products/ai/)
* [PyTorch](https://pytorch.org/)
* [TensorFlow](https://www.tensorflow.org/)

### Supplemental Notes on Tools

1. [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb), "a free Jupyter notebook environment that requires no setup and runs entirely in the cloud", has a lot to love, but in particular comes with an interactive notebook version of Jake VanderPlas's book, [_Python Data Science Handbook: Essential Tools for Working with Data_](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb#scrollTo=sA1kJOJhW-Ge), and links to the self-paced website, [_Machine Learning Crash Course_](https://developers.google.com/machine-learning/crash-course/) by Google

2. Google Cloud Platform has excellent self-paced material in its [Google Cloud Training Platform](https://cloud.google.com/training/), which includes labs through Qwiklabs and three [Data and Machine Learning](https://cloud.google.com/training/data-ml) learning tracks: one for data analysts, one for data engineering, and one for data scientists

3. For one opinion on PyTorch vs TensorFlow, see ["Tensorflow or PyTorch : The force is strong with which one?
"](https://medium.com/@UdacityINDIA/tensorflow-or-pytorch-the-force-is-strong-with-which-one-68226bb7dab4) by Yashwardhan Jain

## Acknowledgements of Awesome Humans
Thanks to Kellen B., Chris Ca., Erica C., Chris Co., Clayton C., Adham E., Jacob E., Tamra G., Cassandra H., Rafi K., Dr. Yogesh M., Daniel M., Ray Me., Ray Mo., Robert M., Stephan P., Tim S., Jorden S., Sami V., Wesley W., Jaylen W., Brandon W., and others for the wonderful suggestions and resources and for helping to bootstrap my machine learning journey with your excellent recommendations. Extra special thank you to Mark C. for many of the People suggestions above, and for a copy of _The Master Algorithm_.
