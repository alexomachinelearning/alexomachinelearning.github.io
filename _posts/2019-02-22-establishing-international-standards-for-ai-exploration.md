---
layout: post
title: "Establishing International Standards for AI Exploration"
date:   2019-02-22 12:00:00 -0800

---
NASA has a job called *Planetary Protection Officer*. The work involves what I imagine includes thinking about and protecting the Earth ecosystem from worst-case scenarios, specifically those pertaining to "biological contamination in human and robotic space exploration" (["NASA HQ Planetary Protection Officer", 2017](https://astrobiology.nasa.gov/careers-employment/nasa-hq-planetary-protection-officer/)). The scope of work is both inbound and outbound in nature: for example, we don't want Mars Curiosity Rover, [if ever returned back to Earth](https://theweek.com/articles/471013/curiosity-rover-ever-come-back-earth), introducing anything new into Earth's biosphere, remote as the odds of that would be, any more than we want to contaminate Mars with stuff that originated on Earth, despite there being no life there, just as a matter of two-way responsibility.

Exotic as the job title may seem, there's actually a dotted line between it and decisions made 50+ years ago regarding space exploration. From Article IX of the Resolution Adopted by the General Assembly of the United Nations in 1966, _Treaty on Principles Governing the Activities of States in the Exploration and Use of Outer Space, including the Moon and Other Celestial Bodies_, aka the [Outer Space Treaty](https://en.wikipedia.org/wiki/Outer_Space_Treaty):

> States Parties to the Treaty shall pursue studies of outer space, including the moon and other celestial bodies, and conduct exploration of them so as to avoid their harmful contamination and also adverse changes in the environment of the Earth resulting from the introduction of extraterrestrial matter and, where necessary, shall adopt appropriate measures for this purpose.

These sorts of things were being talked about during the early days of modern computing and space exploration (unrelatedly, but interesting to note, in the time before public-key infrastructure, distributed databases, and other components of the modern space technology stack at that). So it isn't too early for us to establish similar discussions today regarding technological scenarios in AI exploration that might not be too far-fetched fifty years from now.

As machine learning technologies improve and more advanced general AI becomes feasible in upcoming years and decades, in particular those technologies that can create their own algorithms, generate content and business decisions, or build long-lived software, and out of an abundance of both caution and good common sense, nations might consider establishing international principles and also appointing someone at a national level to the task of thinking about the worst that could happen, and how to pre-empt it.

Anything less would be needlessly short-sighted and unwise.
