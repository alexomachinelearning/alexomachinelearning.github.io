---
layout: post
title: "My In-Depth Introduction to Deep Learning Basics (Part 1)"
date:   2019-01-21 12:00:00 -0800

---
In ["Resources for the Newcomer to Machine Learning"](https://ahumanlearningmachinelearning.com/2019/01/02/resources-for-the-newcomer-to-machine-learning/), I listed Lex Fridman as one of the folks newcomers like me to this space should follow as a resource. He teaches an MIT course whose latest session began only recently. The first set of slides from the course is [up for all to see](https://www.dropbox.com/s/c0g3sc1shi63x3q/deep_learning_basics.pdf?dl=0#), as is the [video recording](https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&v=O5xeyoRL95U) of the first lecture and a [GitHub repository](https://github.com/lexfridman/mit-deep-learning) with tutorials and other resources.

First, some impressions on the slides: they are outstanding. Right away, the begin to generate value for the leander. On the second slide (S2), the slideshow highlights what **deep learning** is all about: what it is, how it's done, tools used to train and use deep learning models, what's difficult about deep learning, why deep learning has become so popular, a zoomed-out view of where the deep learning community currently stands, and 11 examples of use cases and applications for the deep learning state-of-the-art.

There are two standout bullet points on that same slide:

1. *"Good Questions + Good Data"*
2. *"Most big questions of intelligence have not been answered nor properly formulated"*

The first selection is a standout because it's another reminder of the criticality of asking good questions, essential to all science. See my article ["On Asking the Right Questions and Asking Questions the Right Way"](https://ahumanlearningmachinelearning.com/2019/01/09/on-asking-the-right-questions-and-asking-questions-the-right-way/)) for my exploration of this topic.

The second selection is a standout because it belies something cool, which is this: most of the exciting findings and applications of deep learning (and machine learning generally) _have not yet found_...because the biggest and best questions in machine learning have not yet been asked. I would extend that to say that the biggest and best questions in human learning have not yet been asked either: neuroscience is still a very young discipline. We are at the outset, at the base of the mountain, of what there is to know about the human brain and human learning. Consider, then, that to understand machines and what they are capable of us having them do for us, we must first understand ourselves. We barely do, but imagine what will become possible once that changes.

## Sliding into Deep Learning

Pleasantly, as I began to read through Fridman's slide show, I spotted many concepts that I've recently encountered or written about at this early stage of my learning process. There were enough of these that I thought it offered me a great opportunity to re-engage with those recent knowledge-hooks and tap into the power of [spaced repetition](https://en.wikipedia.org/wiki/Spaced_repetition)). I thought it also served as a great exercise in making associations that, be they to turn out to be valid or errant, are important to learning. So below I share some of what I observed as I read through the first 40% of Fridman's slides (note that *S* stands for "slide"):

- **S4**: this mentions the invention of the perceptron in '57 (by Frank Rosenblatt, which I wrote about in ["A Little on Early History in Machine Learning"](https://ahumanlearningmachinelearning.com/2019/01/05/a-little-on-early-history-in-machine-learning/))
- **S5**: here you can see a sweet picture of Rosenblatt messing around with the cables (presumably the cables that connected the "retinal units" to the "association units") of his Mark I Perceptron from 1960. It's also fascinating that PyTorch and TensorFlow have only been around for 2-4 years (these came up, along with Caffe, in ["Advice on Selecting Programming Languages for Working with Neural Networks"](https://ahumanlearningmachinelearning.com/2019/01/06/advice-on-selecting-programming-languages-for-working-with-neural-networks/"))
- **S6**: this slide shows an awesome walkthrough of some basic code in Python involving TensorFlow and Keras. As best I can tell, the key steps to training the model in the example shown involve a) getting training data, b) setting up the learning model, c) training the model, d) evaluating the results after (five?) training sessions, and then e) making predictions on (new?) images. Per line 7, the code loads MNIST training data (see my post ["My Python Journey Began Today (and Why Python)"](https://ahumanlearningmachinelearning.com/2019/01/11/my-python-journey-began-today-and-why-python/), wherein I mention the Michael Nielsen MNIST walkthrough used by 3Blue1Brown in his famous video on deep learning). Speaking of 3Blue1Brown's video, which includes a discussion on ReLU vs Sigmoid "squishification" functions, on line 12 of this slide, you can see a reference to "ReLU" as the activation function used
- **S8**: an image is shown of a person, and a basic architecture of a neural network (NN) is described. The NN has an input layer, three hidden layers, and an output layer, wherefrom the models' prediction is given. What I like about this slide is that it shows how the 1st hidden layer identifies "edges"; the 2nd hidden layer identifies "corners and contours"; and the 3rd hidden layer identifies "object parts". In ["Should Machines Learn to Process Speech before They Learn to Process Text?"](https://ahumanlearningmachinelearning.com/2019/01/03/should-machines-learn-to-process-speech-before-they-learn-to-process-text/), I reflected on auditory and visual primitives, i.e., building blocks, which Ethem Alpaydin in his book _Machine Learning_ discusses in the context of _hierarchical processing_. What "arcs and line segments" are to handwritten letters in the example given by Alpaydin, "edges" are to visual images in the _representation learning_ depicted on this deep learning slide: the features to be learned and assembled successively as the number of neural network layers increases
- **S10**: This has a high probably of being completely unrelated, but something about this image reminds me of _autoencoder (AE) networks_
- **S18**: (Definitely completely unrelated, but the last bullet point on here regarding humor, i.e., of examples of what we [humans] can't do well, reminds me that one of the theories of what makes things funny is that we can't predict the punchlines. See "[benign violation theory](https://en.wikipedia.org/wiki/Theories_of_humor#Benign_violation_theory)". Assuming the theory holds true, if we _could_ come to ever predict all conversations, then we probably [_should not_ allow ourselves to ever create such a capability](https://ahumanlearningmachinelearning.com/2019/01/14/there-may-never-be-a-reliable-way-to-predict-all-conversations/)â€”if for no other reason than that comedy would forever cease to be funny)
- **S20**: Nice! I recently bought and started reading Max Tegmark's [_LIFE 3.0_](https://www.amazon.com/gp/product/1101970316) but haven't made much progress on it yet. However, this slide includes what I now see is on p. 53 of his book: "Figure 2.2: Illustration of Hans Moravec's 'landscape of human competence,' where elevation represents difficulty for computers, and the rising sea level represents what computers are able to do". From the shared visual in Fridman's slide here and Tegmark's book, art and science are depicted as the pinnacles of human accomplishment (though why Moravec chose to make Science slightly higher in amplitude than Art is something to investigate!)
- **S23**: this is an excellent image that seems to capture, quite helpfully, the relative degree of involvement by human researchers in the learning model training process depending on the **learning type** (see my post ["Buckets of Concepts About Learning Machines"](https://ahumanlearningmachinelearning.com/2019/01/04/buckets-of-concepts-about-learning-machines/), where I expressed confusion about the right way for me to conceptualize the bucket of learning type). Based on this image and the one on Slide 12, I might revise my understanding of learning type to be more at, "a relative measure of the level of involvement (if at all) of a human in feature extraction conducted by a learning model during the training process."

I'll continue this approach to my introduction to deep learning tomorrow.
